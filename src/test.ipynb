{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "def vct_db_filename_gen(file_path):\n",
    "    # Derive vector DB filename from CSV filename\n",
    "    base_name = os.path.basename(file_path)\n",
    "    db_file_name = os.path.splitext(base_name)[0] + \".vecdb\"\n",
    "\n",
    "    return os.path.join(os.path.dirname(file_path), db_file_name)\n",
    "\n",
    "def check_and_load_vector_db(file_path, embedding):\n",
    "    \"\"\"\n",
    "    Checks if a vector db file exists for the given file_path, \n",
    "    loads it if exists, otherwise creates it from the csv and saves it.\n",
    "    \"\"\"\n",
    "    # Derive vector DB filename from CSV filename\n",
    "    db_file_path = vct_db_filename_gen(file_path)\n",
    "\n",
    "    # Check if the vector DB file exists\n",
    "    if os.path.exists(db_file_path):\n",
    "        print(f\"Loading existing vector DB from {db_file_path}\")\n",
    "        db = Chroma(persist_directory=db_file_path, embedding_function=embedding)\n",
    "    else:\n",
    "        print(f\"Vector DB not found. Creating from {file_path}\")\n",
    "        # Load the CSV and create the vector DB\n",
    "        loader = CSVLoader(file_path=file_path)\n",
    "        documents = loader.load()\n",
    "        # Save the newly created vector DB\n",
    "        db = Chroma.from_documents(documents, embedding, persist_directory=db_file_path)\n",
    "        print(f\"Saved new vector DB to {db_file_path}\")\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsData:\n",
    "    def __init__(self, chain_type, time=None, tokens_used=None, example_number=None, predicted_query=None, predicted_answer=None, answer=None, result=None):\n",
    "        self.chain_type = chain_type\n",
    "        self.eval = []\n",
    "        if example_number is not None:\n",
    "            self.append_evaluation(time, tokens_used, example_number, predicted_query, answer, predicted_answer, result)\n",
    "    \n",
    "    def append_evaluation(self, time, tokens_used, example_number, predicted_query, answer, predicted_answer, result):\n",
    "        \"\"\"Append a new evaluation result to the eval list.\"\"\"\n",
    "        self.eval.append({\n",
    "            \"time\": time,\n",
    "            \"tokens_used\": tokens_used,\n",
    "            \"example_number\": example_number,\n",
    "            \"query\": predicted_query,\n",
    "            \"predicted_answer\": predicted_answer,\n",
    "            \"answer\": answer,\n",
    "            \"result\": result\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# account for deprecation of LLM model\n",
    "\n",
    "def llm_model():\n",
    "    # Get the current date\n",
    "    current_date = datetime.datetime.now().date()\n",
    "\n",
    "    # Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "    target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "    # Set the model variable based on the current date\n",
    "    if current_date > target_date:\n",
    "        return \"gpt-3.5-turbo\"\n",
    "    else:\n",
    "        return \"gpt-3.5-turbo-0301\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from modules.set_model import llm_model\n",
    "from langchain_openai import ChatOpenAI\n",
    "from modules.results_data import ResultsData\n",
    "from datetime import datetime\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def langchain_output_parser(qa_output):\n",
    "    \"\"\"\n",
    "    Transforms the QA output from langchain into a dictionary format without the 'qa_pairs' field.\n",
    "    \n",
    "    Parameters:\n",
    "    - qa_output: A list of dictionaries, where each dictionary contains 'qa_pairs' among other possible fields.\n",
    "\n",
    "    Returns:\n",
    "    - A list of dictionaries, where each dictionary directly contains 'query' and 'answer' fields.\n",
    "    \"\"\"\n",
    "    parsed_output = []\n",
    "    for item in qa_output:\n",
    "        # Assuming each item in qa_output is a dictionary with a 'qa_pairs' key\n",
    "        qa_pair = item.get('qa_pairs', {})\n",
    "        # Repackage the qa_pair without the 'qa_pairs' field\n",
    "        reformatted_item = {\n",
    "            'query': qa_pair.get('query', ''),\n",
    "            'answer': qa_pair.get('answer', '')\n",
    "        }\n",
    "        parsed_output.append(reformatted_item)\n",
    "    return parsed_output\n",
    "\n",
    "\n",
    "def generate_qas(file_path, db, llm, chain_type):\n",
    "    # Load vector db to index\n",
    "    loader = CSVLoader(file_path=file_path)\n",
    "    data = loader.load()\n",
    "    index = VectorStoreIndexWrapper(vectorstore=db)\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm, \n",
    "        chain_type=chain_type, \n",
    "        retriever=index.vectorstore.as_retriever(), \n",
    "        verbose=True,\n",
    "        # chain_type_kwargs = {\n",
    "        #     \"document_separator\": \"<<<<>>>>>\"\n",
    "        # }\n",
    "    ) \n",
    "\n",
    "    # LLM-Generated example Q&A pairs \n",
    "    example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI(model=llm_model()))\n",
    "    # the warning below can be safely ignored\n",
    "    raw_examples = example_gen_chain.apply( # create raw examples\n",
    "        [{\"doc\": t} for t in data[:5]],\n",
    "    )\n",
    "\n",
    "    # Parse the raw examples into required format\n",
    "    examples = langchain_output_parser(raw_examples)\n",
    "\n",
    "    # run for manual evaluation\n",
    "    qa.run(examples[0][\"query\"])\n",
    "\n",
    "    return qa, examples\n",
    "\n",
    "def evaluate(chain_type, qa, examples, llm, results_data):\n",
    "    # LLM assisted evaluation\n",
    "\n",
    "    # Measure number of tokens used\n",
    "    #TODO: remove duplication\n",
    "    with get_openai_callback() as cb:\n",
    "        start = datetime.now()\n",
    "\n",
    "        try:\n",
    "            predictions = qa.apply(examples)\n",
    "        except ValueError as e: \n",
    "            response = e\n",
    "\n",
    "        end = datetime.now()\n",
    "        \n",
    "    # Calculate the difference between the end and start timestamps to get the execution duration.\n",
    "    # The duration is converted to milliseconds for a more precise and readable format.\n",
    "    td = (end - start).total_seconds() * 10**3\n",
    "    tokens_used = cb.total_tokens\n",
    "\n",
    "    eval_chain = QAEvalChain.from_llm(llm)\n",
    "    graded_outputs = eval_chain.evaluate(examples, predictions)\n",
    "\n",
    "    # turn to object and return\n",
    "    # using llm as real answer and predicted answer are not similar in a string match sense, e.g. look at example_llm_eval.txt\n",
    "    for i, eg in enumerate(examples):\n",
    "        \n",
    "        example_number = i\n",
    "        query = predictions[i]['query']\n",
    "        answer = predictions[i]['answer']\n",
    "        predicted_answer = predictions[i]['result']\n",
    "        result = graded_outputs[i]['results']\n",
    "        \n",
    "        print(f\"Example {example_number}:\")\n",
    "        print(\"Question: \" + query)\n",
    "        print(\"Real Answer: \" + answer)\n",
    "        print(\"Predicted Answer: \" + predicted_answer)\n",
    "        print(\"Predicted Grade: \" + result)\n",
    "        print()\n",
    "\n",
    "        results_data = add_to_results_list(results_data, chain_type, query, time=td, tokens_used=tokens_used, example_number=i, predicted_answer=predicted_answer, answer=answer, result=result)\n",
    "    return results_data\n",
    "\n",
    "def add_to_results_list(results_data, chain_type, query, time=None, tokens_used=None, example_number=None, answer=None, predicted_answer=None, result=None):\n",
    "    found = False\n",
    "    for item in results_data:\n",
    "        if item.chain_type == chain_type:\n",
    "            # Update the existing dictionary\n",
    "            item.append_evaluation(time=time, tokens_used=tokens_used, example_number=example_number, \n",
    "                         predicted_query=query, answer=answer, predicted_answer=predicted_answer, result=result)\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if not found:\n",
    "        # Append a new instance of ResultsData if no matching chain_type was found\n",
    "        results_data.append(ResultsData(chain_type=chain_type, time=time, tokens_used=tokens_used, \n",
    "                                        example_number=example_number, predicted_query=query, \n",
    "                                        answer=answer, predicted_answer=predicted_answer, \n",
    "                                        result=result))\n",
    "        \n",
    "    return results_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def qa_analysis(llm, chain_type, retriever, verbose, query, number, results_data):\n",
    "    \"\"\"\n",
    "    Initializes a QA analysis with a given language model, chain type, and retriever.\n",
    "    Then, it runs the QA analysis, timing its execution and printing the response along with the execution time.\n",
    "    \"\"\"\n",
    "    # Initialize the RetrievalQA object with the specified parameters.\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm, \n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    # Measure number of tokens used\n",
    "    with get_openai_callback() as cb:\n",
    "        start = datetime.datetime.now()\n",
    "\n",
    "        try:\n",
    "            # Execute the QA analysis\n",
    "            response = qa.invoke(query) #TODO: i've only added queries, no answers...\n",
    "        except ValueError as e: \n",
    "            response = e\n",
    "\n",
    "        end = datetime.datetime.now()\n",
    "    \n",
    "    tokens_used = cb.total_tokens\n",
    "\n",
    "    # Calculate the difference between the end and start timestamps to get the execution duration.\n",
    "    # The duration is converted to milliseconds for a more precise and readable format.\n",
    "    td = (end - start).total_seconds() * 10**3\n",
    "    \n",
    "    print(f\"Response: {response}\\nThe time of execution of above program is : {td:.03f}ms\")\n",
    "\n",
    "    results_data = add_to_results_list(results_data, chain_type, query, td, tokens_used, number, response)\n",
    "\n",
    "    print(\"\\n\\nTESTING\\n:\" + '\\n'.join([str(item) for item in results_data]))\n",
    "\n",
    "    return results_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_data_to_markdown_table(results_data_list):\n",
    "    headers = [\"Chain Type\", \"Eval Time\", \"Tokens Used\", \"Example Number\", \"Predicted Query\", \"Predicted Answer\", \"Answer\", \"Result\"]\n",
    "    markdown_table = \"| \" + \" | \".join(headers) + \" |\\n\"\n",
    "    markdown_table += \"| \" + \" | \".join([\"---\"] * len(headers)) + \" |\\n\"\n",
    "\n",
    "    for data in results_data_list:\n",
    "        for eval in data.eval:\n",
    "            # Ensure every value is a string, handling None and ensuring dict values are properly formatted or avoided\n",
    "            row = [\n",
    "                data.chain_type,\n",
    "                str(eval.get(\"time\", \"\")),\n",
    "                str(eval.get(\"tokens_used\", \"\")),\n",
    "                str(eval.get(\"example_number\", \"\")),\n",
    "                eval.get(\"query\", \"\"),\n",
    "                eval.get(\"predicted_answer\", \"\") if eval.get(\"predicted_answer\") is not None else \"\",\n",
    "                eval.get(\"answer\", \"\"),\n",
    "                eval.get(\"result\", \"\") if eval.get(\"result\") is not None else \"\"\n",
    "            ]\n",
    "            markdown_table += \"| \" + \" | \".join([str(item) for item in row]) + \" |\\n\"\n",
    "    \n",
    "    return markdown_table\n",
    "\n",
    "\n",
    "def write_markdown_table_to_file(markdown_table, filename):\n",
    "    # Write the markdown table to the specified file\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(markdown_table)\n",
    "    \n",
    "    print(f\"Markdown table successfully written to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector DB from ../data/OutdoorClothingCatalog_1000.vecdb\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Example 0:\n",
      "Question: What is the approximate weight of the Women's Campside Oxfords per pair?\n",
      "Real Answer: The approximate weight of the Women's Campside Oxfords per pair is 1 lb.1 oz.\n",
      "Predicted Answer: The approximate weight of the Women's Campside Oxfords per pair is 1 lb. 1 oz.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 1:\n",
      "Question: What percentage of recycled materials is the polyester fabric made of in the Recycled Waterhog Dog Mat?\n",
      "Real Answer: The polyester fabric in the Recycled Waterhog Dog Mat is made from 94% recycled materials.\n",
      "Predicted Answer: The polyester fabric in the Recycled Waterhog Dog Mat is made from 94% recycled materials.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 2:\n",
      "Question: What features does the Infant and Toddler Girls' Coastal Chill Swimsuit have for sun protection?\n",
      "Real Answer: The Infant and Toddler Girls' Coastal Chill Swimsuit has UPF 50+ rated fabric that provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays.\n",
      "Predicted Answer: The Infant and Toddler Girls' Coastal Chill Swimsuit has UPF 50+ rated fabric which provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 3:\n",
      "Question: What is the fabric composition of the Refresh Swimwear V-Neck Tankini Contrasts?\n",
      "Real Answer: The Refresh Swimwear V-Neck Tankini Contrasts is made of 82% recycled nylon with 18% Lycra® spandex for the body and 90% recycled nylon with 10% Lycra® spandex for the lining.\n",
      "Predicted Answer: The Refresh Swimwear V-Neck Tankini Contrasts is made of 82% recycled nylon with 18% Lycra® spandex for the body and 90% recycled nylon with 10% Lycra® spandex for the lining.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 4:\n",
      "Question: What is the main feature of the EcoFlex 3L Storm Pants?\n",
      "Real Answer: The main feature of the EcoFlex 3L Storm Pants is the TEK O2 technology which offers the most breathability ever tested and guarantees to keep the wearer dry and comfortable in any weather and activity.\n",
      "Predicted Answer: The main feature of the EcoFlex 3L Storm Pants is the state-of-the-art TEK O2 technology that offers the most breathability ever tested, making them great as ski pants and ideal for a variety of outdoor activities year-round.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Example 0:\n",
      "Question: What is the approximate weight of the Women's Campside Oxfords?\n",
      "Real Answer: The approximate weight of the Women's Campside Oxfords is 1 lb. 1 oz. per pair.\n",
      "Predicted Answer: I'm sorry, there is no information about the approximate weight of the Women's Campside Oxfords in the given portion of the document.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 1:\n",
      "Question: What materials are used to construct the Recycled Waterhog dog mat?\n",
      "Real Answer: The Recycled Waterhog dog mat is constructed from 24 oz. polyester fabric made from 94% recycled materials and has a rubber backing.\n",
      "Predicted Answer: There is no information provided in the given portion of the document about the Recycled Waterhog dog mat.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 2:\n",
      "Question: What is the UPF rating for the fabric of the Infant and Toddler Girls' Coastal Chill Swimsuit?\n",
      "Real Answer: The UPF 50+ rated fabric provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays.\n",
      "Predicted Answer: There is no information provided about the UPF rating for the Infant and Toddler Girls' Coastal Chill Swimsuit in the given portion of the document.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 3:\n",
      "Question: What is the fabric composition of the Refresh Swimwear V-Neck Tankini Contrasts?\n",
      "Real Answer: The body is made of 82% recycled nylon with 18% Lycra® spandex, while the lining is made of 90% recycled nylon with 10% Lycra® spandex.\n",
      "Predicted Answer: The body of the Refresh Swimwear V-Neck Tankini Contrasts is made of 82% recycled nylon and 18% Lycra® spandex, while the lining is made of 90% recycled nylon and 10% Lycra® spandex.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 4:\n",
      "Question: What is the technology used in EcoFlex 3L Storm Pants and how does it benefit the wearer?\n",
      "Real Answer: The technology used in EcoFlex 3L Storm Pants is TEK O2 technology, which offers the most breathability ever tested. It keeps the wearer dry and comfortable, regardless of the activity or weather.\n",
      "Predicted Answer: The technology used in EcoFlex 3L Storm Pants is TEK O2, which offers enhanced breathability and waterproof protection. It benefits the wearer by keeping them dry and comfortable during outdoor activities, and is ideal for year-round use. The pants also feature weather-blocking gaiters and side zips for easy on/off over boots.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Example 0:\n",
      "Question: What is the approximate weight of the Women's Campside Oxfords?\n",
      "Real Answer: The approximate weight of the Women's Campside Oxfords is 1 lb.1 oz. per pair.\n",
      "Predicted Answer: The new context provided is not useful for refining the original answer as it pertains to a different product (Men's Rockport Reflection Oxfords) and not the Women's Campside Oxfords. Therefore, the original answer remains the same: The approximate weight of the Women's Campside Oxfords is 1 lb. 1 oz. per pair.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 1:\n",
      "Question: What are the dimensions of the small and medium Recycled Waterhog Dog Mats?\n",
      "Real Answer: The small mat has dimensions of 18\" x 28\" and the medium mat has dimensions of 22.5\" x 34.5\".\n",
      "Predicted Answer: The given context is not related to the original question about the dimensions of the small and medium Recycled Waterhog Dog Mats. Therefore, the original answer remains the same.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 2:\n",
      "Question: What are some features of the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece?\n",
      "Real Answer: The swimsuit features bright colors, ruffles, and exclusive whimsical prints. It is made of a four-way-stretch and chlorine-resistant fabric that keeps its shape and resists snags. The fabric is UPF 50+ rated, providing the highest rated sun protection possible, blocking 98% of the sun's harmful rays. It has crossover no-slip straps and a fully lined bottom to ensure a secure fit and maximum coverage. The swimsuit can be machine washed and line dried for best results and is imported.\n",
      "Predicted Answer: The new context is not related to the original question about the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece. Therefore, the original answer remains the same.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 3:\n",
      "Question: What is the material composition of the Refresh Swimwear, V-Neck Tankini Contrasts?\n",
      "Real Answer: The body of the swimwear is made of 82% recycled nylon and 18% Lycra® spandex, while the lining is made of 90% recycled nylon and 10% Lycra® spandex.\n",
      "Predicted Answer: The material composition of the Mix-It-Up Tankini Print is 80% nylon and 20% Lycra® Xtra Life for the fabric, and 84% nylon and 16% Lycra Elastane for the lining. The fabric is designed to provide long-lasting fit and resistance to sun, chlorine, and heat up to 10 times longer than unprotected fabrics. The lining provides UPF 50+ rated sun protection. The Italian swim fabric is breathable, quick-drying, and chlorine-resistant for stay-true color. The fabric is recommended by The Skin Cancer Foundation as an effective UV protectant.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "Example 4:\n",
      "Question: What is the technology used in the EcoFlex 3L Storm Pants?\n",
      "Real Answer: The EcoFlex 3L Storm Pants use TEK O2 technology, which offers the most breathability tested by the company.\n",
      "Predicted Answer: The original answer is not related to the new context provided. It is about the technology used in the EcoFlex 3L Storm Pants, while the new context is about the SnowShield Pants. Therefore, the original answer remains the same.\n",
      "Predicted Grade: INCORRECT\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Example 0:\n",
      "Question: What is the approximate weight of the Women's Campside Oxfords per pair?\n",
      "Real Answer: The approximate weight of the Women's Campside Oxfords per pair is 1 lb.1 oz.\n",
      "Predicted Answer: Approx. weight: 1 lb.1 oz. per pair.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 1:\n",
      "Question: What are the dimensions of the small and medium Recycled Waterhog dog mats?\n",
      "Real Answer: The small Recycled Waterhog dog mat has dimensions of 18\" x 28\" and the medium has dimensions of 22.5\" x 34.5\".\n",
      "Predicted Answer: Small - Dimensions: 18\" x 28\". Medium - Dimensions: 22.5\" x 34.5\".\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 2:\n",
      "Question: What are the features of the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece?\n",
      "Real Answer: The swimsuit features bright colors, ruffles, and exclusive whimsical prints. It is made of four-way-stretch and chlorine-resistant fabric that resists snags. The swimsuit is UPF 50+ rated, providing the highest rated sun protection possible, blocking 98% of the sun's harmful rays. It has a crossover no-slip straps and fully lined bottom to ensure a secure fit and maximum coverage. The swimsuit can be machine washed and line dried for best results. It is imported.\n",
      "Predicted Answer: The features of the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece include bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom, and machine wash and line dry for best results. \n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 3:\n",
      "Question: What is the fabric composition of the Refresh Swimwear, V-Neck Tankini Contrasts?\n",
      "Real Answer: The Refresh Swimwear, V-Neck Tankini Contrasts is made of 82% recycled nylon with 18% Lycra® spandex for the body and 90% recycled nylon with 10% Lycra® spandex for the lining.\n",
      "Predicted Answer: Body in 82% recycled nylon with 18% Lycra® spandex. Lined in 90% recycled nylon with 10% Lycra® spandex.\n",
      "Predicted Grade: CORRECT\n",
      "\n",
      "Example 4:\n",
      "Question: What is the technology used in the EcoFlex 3L Storm Pants and how does it work?\n",
      "Real Answer: The technology used in the EcoFlex 3L Storm Pants is TEK O2, which offers enhanced breathability and keeps the wearer dry and comfortable by allowing air in and water out.\n",
      "Predicted Answer: The technology used in the EcoFlex 3L Storm Pants is TEK O2, which offers enhanced breathability and keeps the wearer dry and comfortable. The technology is air-permeable, allowing air to flow through while keeping water out. \n",
      "Predicted Grade: CORRECT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "    # Basic Setup\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "results_data = []\n",
    "strategies = [\"stuff\", \"map_reduce\", \"refine\", \"map_rerank\"]\n",
    "\n",
    "# Load data into vector db or use existing one\n",
    "file_path = '../data/OutdoorClothingCatalog_1000.csv'\n",
    "embedding = OpenAIEmbeddings()  # Define embedding\n",
    "\n",
    "# Check if vector DB exists for the CSV, and load or create accordingly\n",
    "db = check_and_load_vector_db(file_path, embedding)\n",
    "\n",
    "queries = [\"Please suggest a shirt with sunblocking\", \"Please suggest a shirt with sunblocking and tell me why this one\", \"Please suggest three shirts with sunblocking and tell me why. Give this back to me in markdown code as a table\", \"Please suggest three shirts with sunblocking and tell me why. Give this back to me in markdown code as a table, with a summary below outlining why sunblocking is important\"]\n",
    "\n",
    "# Configure LLM for querying\n",
    "# layers vector db on llm to inform decisions and responses\n",
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model())\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# Manual analysis - TODO: add answers\n",
    "# for index, query in enumerate(queries, start=1):\n",
    "#     results_data = qa_analysis(llm, \"stuff\", retriever, True, query, index, results_data)\n",
    "#     results_data = qa_analysis(llm, \"map_reduce\", retriever, True, query, index, results_data)\n",
    "#     results_data = qa_analysis(llm, \"refine\", retriever, True, query, index, results_data)\n",
    "#     results_data = qa_analysis(llm, \"map_rerank\", retriever, True, query, index, results_data)\n",
    "\n",
    "# LLM QA Gen AND Evaluate\n",
    "for strat in strategies:\n",
    "    # Generate evaluation Q&As\n",
    "    tuple = generate_qas(file_path, db, llm, strat)\n",
    "    qa = tuple[0]\n",
    "    examples = tuple[1]\n",
    "\n",
    "    # Evaluate \n",
    "    results_data = evaluate(strat, qa, examples, llm, results_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Generate results in markdown\n",
    "md_table = results_data_to_markdown_table(results_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown table successfully written to results.md\n"
     ]
    }
   ],
   "source": [
    "    # Write results to file\n",
    "write_markdown_table_to_file(md_table, \"results.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[{'query': \"What is the approximate weight of the Women's Campside Oxfords per pair?\", 'answer': \"The approximate weight of the Women's Campside Oxfords per pair is 1 lb.1 oz.\", 'result': 'Approx. weight: 1 lb.1 oz. per pair.'}, {'query': 'What are the dimensions of the small and medium Recycled Waterhog dog mats?', 'answer': 'The small Recycled Waterhog dog mat has dimensions of 18\" x 28\" and the medium has dimensions of 22.5\" x 34.5\".', 'result': 'Small - Dimensions: 18\" x 28\". Medium - Dimensions: 22.5\" x 34.5\".'}, {'query': \"What are the features of the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece?\", 'answer': \"The swimsuit features bright colors, ruffles, and exclusive whimsical prints. It is made of four-way-stretch and chlorine-resistant fabric that resists snags. The swimsuit is UPF 50+ rated, providing the highest rated sun protection possible, blocking 98% of the sun's harmful rays. It has a crossover no-slip straps and fully lined bottom to ensure a secure fit and maximum coverage. The swimsuit can be machine washed and line dried for best results. It is imported.\", 'result': \"The features of the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece include bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom, and machine wash and line dry for best results. \"}, {'query': 'What is the fabric composition of the Refresh Swimwear, V-Neck Tankini Contrasts?', 'answer': 'The Refresh Swimwear, V-Neck Tankini Contrasts is made of 82% recycled nylon with 18% Lycra® spandex for the body and 90% recycled nylon with 10% Lycra® spandex for the lining.', 'result': 'Body in 82% recycled nylon with 18% Lycra® spandex. Lined in 90% recycled nylon with 10% Lycra® spandex.'}, {'query': 'What is the technology used in the EcoFlex 3L Storm Pants and how does it work?', 'answer': 'The technology used in the EcoFlex 3L Storm Pants is TEK O2, which offers enhanced breathability and keeps the wearer dry and comfortable by allowing air in and water out.', 'result': 'The technology used in the EcoFlex 3L Storm Pants is TEK O2, which offers enhanced breathability and keeps the wearer dry and comfortable. The technology is air-permeable, allowing air to flow through while keeping water out. '}]\n"
     ]
    }
   ],
   "source": [
    "predictions = qa.apply(examples)\n",
    "\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
